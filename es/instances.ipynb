{
  "cells": [
    {
      "attachments": {
      },
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "## Instancias y extensiones"
      ]
    },
    {
      "attachments": {
      },
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "Este capítulo cubrirá varios algoritmos variacionales cuánticos, que incluyen:\n",
        "\n",
        "- [Solucionador propio cuántico variacional (VQE)](https://arxiv.org/abs/1304.3061)\n",
        "- [Búsqueda subespacial VQE (SSVQE)](https://arxiv.org/abs/1810.09434)\n",
        "- [Deflación cuántica variacional (VQD)](https://arxiv.org/abs/1805.08138)\n",
        "- [Regresión de muestreo cuántico (QSR)](https://arxiv.org/pdf/2012.02338)\n",
        "\n",
        "Mediante el uso de estos algoritmos, aprenderemos sobre varias ideas de diseño que se pueden incorporar en algoritmos variacionales personalizados, como pesos, penalizaciones, sobremuestreo y submuestreo. Lo alentamos a que experimente con estos conceptos y comparta sus hallazgos con la comunidad."
      ]
    },
    {
      "attachments": {
      },
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "## Solucionador propio cuántico variacional (VQE)\n",
        "\n",
        "[VQE](https://arxiv.org/abs/1304.3061) es uno de los algoritmos cuánticos variacionales más utilizados, configurando una plantilla para que se desarrollen otros algoritmos.\n",
        "\n",
        "![VQE](images/instances_VQE.png)"
      ]
    },
    {
      "attachments": {
      },
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "El diseño de VQE es simple:\n",
        "\n",
        "- Preparar operadores de referencia $U_R$\n",
        "    - Partimos del estado $|0\\rangle$ y vamos al estado de referencia $|\\rho\\rangle$\n",
        "- Aplique la forma variacional $U_V(\\vec\\theta_{i,j})$ para crear un ansatz $U_A(\\vec\\theta_{i,j})$\n",
        "    - Pasamos del estado $|\\rho\\rangle$ a $U_V(\\vec\\theta_{i,j})|\\rho\\rangle = |\\psi(\\vec\\theta_{i,j})\\rangle$\n",
        "- Bootstrap en $i=0$ si tenemos un problema similar (generalmente encontrado a través de simulación clásica o muestreo)\n",
        "    - Cada optimizador se arrancará de forma diferente, lo que dará como resultado un conjunto inicial de vectores de parámetros $\\Theta_0 := \\{ {\\vec\\theta_{0,j} | j \\in \\mathcal{J}_\\text{opt}^0} \\}$ (por ejemplo, desde un punto inicial $\\vec\\theta_0$).\n",
        "- Evalúa la función de costo $C(\\vec\\theta_{i,j}) := \\langle \\psi(\\vec{\\theta}) | \\sombrero{H} | \\psi(\\vec{\\theta})\\rangle$ para todos los estados preparados en una computadora cuántica.\n",
        "- Utilice un optimizador clásico para seleccionar el siguiente conjunto de parámetros $\\Theta_{i+1}$.\n",
        "- Repita el proceso hasta que se alcance la convergencia.\n",
        "\n",
        "Este es un ciclo de optimización clásico simple donde evaluamos la función de costo. Algunos optimizadores pueden requerir múltiples evaluaciones para calcular un gradiente, determinar la siguiente iteración o evaluar la convergencia.\n",
        "\n",
        "Aquí está el ejemplo para el siguiente observable:\n",
        "\n",
        "$$\n",
        "\\hat{O}_1 = 2 II - 2 XX + 3 YY - 3 ZZ,\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "uses-hardware"
        ]
      },
      "outputs": [

      ],
      "source": [
        "from qiskit.circuit.library import TwoLocal\n",
        "from qiskit.quantum_info import SparsePauliOp\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit_ibm_runtime import QiskitRuntimeService, Estimator\n",
        "import numpy as np\n",
        "\n",
        "# Add your token below\n",
        "service = QiskitRuntimeService(\n",
        "    channel=\"ibm_quantum\",\n",
        ")\n",
        "\n",
        "def cost_function_vqe(theta):\n",
        "    observable = SparsePauliOp.from_list([(\"II\", 2), (\"XX\", -2), (\"YY\", 3), (\"ZZ\", -3)])\n",
        "    reference_circuit = QuantumCircuit(2)\n",
        "    reference_circuit.x(0)\n",
        "\n",
        "    variational_form = TwoLocal(\n",
        "        2,\n",
        "        rotation_blocks=[\"rz\", \"ry\"],\n",
        "        entanglement_blocks=\"cx\",\n",
        "        entanglement=\"linear\",\n",
        "        reps=1,\n",
        "    )\n",
        "    ansatz = reference_circuit.compose(variational_form)\n",
        "\n",
        "    backend = service.backend(\"ibmq_qasm_simulator\")\n",
        "    \n",
        "    # Use estimator to get the expected values corresponding to each ansatz\n",
        "    estimator = Estimator(session=backend)\n",
        "    job = estimator.run(ansatz, observable, theta)\n",
        "    values = job.result().values\n",
        "\n",
        "    return values"
      ]
    },
    {
      "attachments": {
      },
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "Podemos usar esta función de costo para calcular parámetros óptimos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [

      ],
      "source": [
        "from qiskit.algorithms.optimizers import COBYLA\n",
        "\n",
        "initial_theta = np.ones(8)\n",
        "optimizer = COBYLA()\n",
        "\n",
        "optimizer_result = optimizer.minimize(fun=cost_function_vqe, x0=initial_theta)\n",
        "\n",
        "optimal_parameters = optimizer_result.x\n",
        "print(optimal_parameters)"
      ]
    },
    {
      "attachments": {
      },
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "Finalmente, podemos usar nuestros parámetros óptimos para calcular nuestros valores propios mínimos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [

      ],
      "source": [
        "observable = SparsePauliOp.from_list([(\"II\", 2), (\"XX\", -2), (\"YY\", 3), (\"ZZ\", -3)])\n",
        "reference_circuit = QuantumCircuit(2)\n",
        "reference_circuit.x(0)\n",
        "\n",
        "variational_form = TwoLocal(\n",
        "    2,\n",
        "    rotation_blocks=[\"rz\", \"ry\"],\n",
        "    entanglement_blocks=\"cx\",\n",
        "    entanglement=\"linear\",\n",
        "    reps=1,\n",
        ")\n",
        "ansatz = reference_circuit.compose(variational_form)\n",
        "solution = ansatz.bind_parameters(optimal_parameters)\n",
        "\n",
        "backend = service.backend(\"ibmq_qasm_simulator\")\n",
        "estimator = Estimator(session=backend)\n",
        "job = estimator.run(solution, observable)\n",
        "values = job.result().values\n",
        "\n",
        "experimental_min_eigenvalue = values[0]\n",
        "print(experimental_min_eigenvalue)"
      ]
    },
    {
      "attachments": {
      },
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "## Búsqueda subespacial VQE (SSVQE)\n",
        "\n",
        "[SSVQE](https://arxiv.org/abs/1810.09434) es una variante de VQE que permite obtener los primeros $k$ valores propios de un $\\hat{H}$ observable con valores propios {$\\lambda_0, \\lambda_1,...,\\lambda_{N-1}$}, donde $N\\geq k$. Sin pérdida de generalidad, asumimos que $\\lambda_0&lt;\\lambda_1&lt;...&lt;\\lambda_{N-1}$. SSQVE presenta una nueva idea al agregar pesos para ayudar a priorizar la optimización del término con el mayor peso.\n",
        "\n",
        "![SSVQE](images/instances_SSVQE.png)\n",
        "\n",
        "Para implementar este algoritmo, necesitamos $k$ estados de referencia mutuamente ortogonales `{latex} \\{ |\\rho_j\\rangle \\}_{j=0}^{k-1}` , lo que significa $\\langle \\rho_j | \\rho_l \\rangle = \\delta_{jl}$ para $j,l&lt;k$. Estos estados se pueden construir utilizando operadores de Pauli. La función de costo de este algoritmo es entonces:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "C(\\vec{\\theta})\n",
        "\n",
        "&amp; := \\sum_{j=0}^{k-1} w_j \\langle \\rho_j | U_{V}^{\\dagger}(\\vec{\\theta})\\hat{H} U_{V}(\\vec{\\theta})|\\rho_j \\rangle \\\\[1mm]\n",
        "\n",
        "&amp; := \\sum_{j=0}^{k-1} w_j \\langle \\psi_{j}(\\vec{\\theta}) | \\hat{H} | \\psi_{j}(\\vec{\\theta}) \\rangle \\\\[1mm]\n",
        "\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "donde $w_j$ es un número positivo arbitrario tal que si $j&lt;l&lt;k$ entonces $w_j&gt;w_l$, y $U_V(\\vec{\\theta})$ es la forma variacional definida por el usuario.\n",
        "\n",
        "El algoritmo SSVQE se basa en el hecho de que los estados propios correspondientes a diferentes valores propios son mutuamente ortogonales. Específicamente, el producto interno de $U_V(\\vec{\\theta})|\\rho_j\\rangle$ y $U_V(\\vec{\\theta})|\\rho_l\\rangle$ se puede expresar como:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\langle \\rho_j | U_{V}^{\\dagger}(\\vec{\\theta})U_{V}(\\vec{\\theta})|\\rho_l \\rangle\n",
        "\n",
        "&amp; = \\langle \\rho_j | I |\\rho_l \\rangle \\\\[1mm]\n",
        "\n",
        "&amp; = \\langle \\rho_j | \\rho_l \\rangle \\\\[1mm]\n",
        "\n",
        "&amp; = \\delta_{jl}\n",
        "\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "La primera igualdad se cumple porque $U_{V}(\\vec{\\theta})$ es un operador cuántico y por lo tanto es unitario. La última igualdad se cumple debido a la ortogonalidad de los estados de referencia $|\\rho_j\\rangle$. El hecho de que la ortogonalidad se mantenga a través de transformaciones unitarias está profundamente relacionado con el principio de conservación de la información, tal como se expresa en la ciencia de la información cuántica. Bajo este punto de vista, las transformaciones no unitarias representan procesos donde la información se pierde o se inyecta.\n",
        "\n",
        "Los pesos $w_j$ ayudan a garantizar que todos los estados sean estados propios. Si los pesos son lo suficientemente diferentes, el término con el mayor peso (es decir, $w_0$) tendrá prioridad durante la optimización sobre los demás. Como resultado, el estado resultante $U_{V}(\\vec{\\theta})|\\rho_0 \\rangle$ se convertirá en el estado propio correspondiente a $\\lambda_0$. `{latex} \\{ U_{V}(\\vec{\\theta})|\\rho_j\\rangle \\}_{j=0}^{k-1}` , por tanto, contenida en el subespacio correspondiente a los valores propios {$\\lambda_1,...,\\lambda_{N-1}$}.\n",
        "\n",
        "Aplicando el mismo argumento al resto de los términos, la siguiente prioridad sería entonces el término con peso $w_1$, por lo que $U_{V}(\\vec{\\theta})|\\rho_1 \\rangle$ sería el estado propio correspondiente a $\\lambda_1$, y los demás términos estarían contenidos en el espacio propio de {$\\lambda_2,...,\\lambda_{N-1}$}.\n",
        "\n",
        "Al razonar inductivamente, deducimos que $U_{V}(\\vec{\\theta})|\\rho_j \\rangle$ será un estado propio aproximado de $\\lambda_j$ para $0\\leq j &lt; k$.\n",
        "\n",
        "Los SSVQE se pueden resumir de la siguiente manera:\n",
        "\n",
        "- Prepare varios estados de referencia aplicando un U_R unitario a k estados de base computacional diferentes\n",
        "    - Este algoritmo requiere el uso de $k$ estados de referencia mutuamente ortogonales `{latex} \\{ |\\rho_j\\rangle \\}_{j=0}^{k-1}` , tal que $\\langle \\rho_j | \\rho_l \\rangle = \\delta_{jl}$ para $j,l&lt;k$.\n",
        "- Aplique la forma variacional $U_V(\\vec\\theta_{i,j})$ a cada estado de referencia, dando como resultado el siguiente ansatz $U_A(\\vec\\theta_{i,j})$.\n",
        "- Bootstrap en $i=0$ si hay un problema similar disponible (generalmente se encuentra mediante simulación clásica o muestreo).\n",
        "- Evalúa la función de costo $C(\\vec\\theta_{i,j}) := \\sum_{j=0}^{k-1} w_j \\langle \\psi_{j}(\\vec{\\theta}) | \\sombrero{H} | \\psi_{j}(\\vec{\\theta}) \\rangle$ para todos los estados preparados en una computadora cuántica.\n",
        "    - Esto se puede dividir en el cálculo del valor esperado para un $\\langle \\psi_{j}(\\vec{\\theta}) | \\sombrero{H} | \\psi_{j}(\\vec{\\theta}) \\rangle$ y multiplicando ese resultado por $w_j$.\n",
        "    - Luego, la función de costo devuelve la suma de todos los valores esperados ponderados.\n",
        "- Utilice un optimizador clásico para determinar el siguiente conjunto de parámetros $\\Theta_{i+1}$.\n",
        "- Repita los pasos anteriores hasta lograr la convergencia.\n",
        "\n",
        "¡Reconstruirá la función de costo de SSVQE en la evaluación!"
      ]
    },
    {
      "attachments": {
      },
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "## Deflación cuántica variacional (VQD)\n",
        "\n",
        "[VQD](https://arxiv.org/abs/1805.08138) es un método iterativo que extiende VQE para obtener los primeros $k$ valores propios de un $\\hat{H}$ observable con valores propios {$\\lambda_0, \\lambda_1,...,\\lambda_{N-1}$}, donde $N\\geq k$, en lugar de solo el primero. Para el resto de esta sección, supondremos, sin pérdida de generalidad, que $\\lambda_0\\leq\\lambda_1\\leq...\\leq\\lambda_{N-1}$. VQD introduce la noción de un costo de penalización para guiar el proceso de optimización.\n",
        "\n",
        "![VQD](images/instances_VQD.png)"
      ]
    },
    {
      "attachments": {
      },
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "VQD introduce un término de penalización, denominado $\\beta$, para equilibrar la contribución de cada término superpuesto al costo. Este término de penalización sirve para penalizar el proceso de optimización si no se logra la ortogonalidad. Imponemos esta restricción porque los estados propios de un observable, o un operador hermitiano, correspondientes a diferentes valores propios son siempre ortogonales entre sí, o se puede hacer que lo sean en el caso de degeneración o valores propios repetidos. Por lo tanto, al hacer cumplir la ortogonalidad con el estado propio correspondiente a $\\lambda_0$, estamos optimizando efectivamente sobre el subespacio que corresponde al resto de los valores propios {$\\lambda_1, \\lambda_2,..., \\lambda_{N-1}$ }. Aquí, $\\lambda_1$ es el valor propio más bajo del resto de los valores propios y, por lo tanto, la solución óptima del nuevo problema se puede obtener usando el teorema variacional.\n",
        "\n",
        "La idea general detrás de VQD es usar VQE como de costumbre para obtener el valor propio más bajo $\\lambda_0 := C_0(\\vec\\theta^0) \\equiv C_\\text{VQE}(\\vec\\theta^0)$ junto con el estado propio correspondiente (aproximado) $|\\psi(\\vec{\\theta^0})\\rangle$ para algún vector de parámetros óptimo $\\vec{\\theta^0}$. Luego, para obtener el siguiente valor propio $\\lambda_1 &gt; \\lambda_0$, en lugar de minimizar la función de costo $C_0(\\vec{\\theta}) := \\langle \\psi(\\vec{\\theta}) | \\sombrero{H} | \\psi(\\vec{\\theta})\\rangle$, optimizamos:\n",
        "\n",
        "$$\n",
        "C_1(\\vec{\\theta}) :=\n",
        "C_0(\\vec{\\theta})+ \\beta_0 |\\langle \\psi(\\vec{\\theta})| \\psi(\\vec{\\theta^0})\\rangle  |^2\n",
        "$$\n",
        "\n",
        "El valor positivo $\\beta_0$ idealmente debería ser mayor que $\\lambda_1-\\lambda_0$.\n",
        "\n",
        "Esto introduce una nueva función de costo que puede verse como un problema restringido, donde minimizamos $C_\\text{VQE}(\\vec{\\theta}) = \\langle \\psi(\\vec{\\theta}) | \\sombrero{H} | \\psi(\\vec{\\theta})\\rangle$ sujeto a la restricción de que el estado debe ser ortogonal al $|\\psi(\\vec{\\theta^0})\\rangle$ obtenido previamente, con $\\beta_0$ actuando como un término de penalización si la restricción no se cumple.\n",
        "\n",
        "Alternativamente, este nuevo problema puede interpretarse como la ejecución de VQE en el nuevo observable:\n",
        "\n",
        "$$\n",
        "\\hat{H_1} := \\hat{H} + \\beta_0 |\\psi(\\vec{\\theta^0})\\rangle \\langle \\psi(\\vec{\\theta^0})|\n",
        "\\quad \\Rightarrow \\quad\n",
        "C_1(\\vec{\\theta}) = \\langle \\psi(\\vec{\\theta}) | \\hat{H_1} | \\psi(\\vec{\\theta})\\rangle,\n",
        "$$\n",
        "\n",
        "Suponiendo que la solución al nuevo problema es $|\\psi(\\vec{\\theta^1})\\rangle$, el valor esperado de $\\hat{H}$ (no $\\hat{H_1}$) debería ser $ \\langle \\psi(\\vec{\\theta^1}) | \\sombrero{H} | \\psi(\\vec{\\theta^1})\\rangle = \\lambda_1$."
      ]
    },
    {
      "attachments": {
      },
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "Para obtener el tercer autovalor $\\lambda_2$, la función de costo a optimizar es:\n",
        "\n",
        "$$\n",
        "C_2(\\vec{\\theta}) :=\n",
        "C_1(\\vec{\\theta}) + \\beta_1 |\\langle \\psi(\\vec{\\theta})| \\psi(\\vec{\\theta^1})\\rangle  |^2\n",
        "$$\n",
        "\n",
        "donde $\\beta_1$ es una constante positiva lo suficientemente grande como para imponer la ortogonalidad del estado de la solución a $|\\psi(\\vec{\\theta^0})\\rangle$ y $|\\psi(\\vec{\\theta^1 })\\ángulo$. Esto penaliza a los estados en el espacio de búsqueda que no cumplen con este requisito, restringiendo efectivamente el espacio de búsqueda. Por tanto, la solución óptima del nuevo problema debería ser el estado propio correspondiente a $\\lambda_2$.\n",
        "\n",
        "Al igual que el caso anterior, este nuevo problema también puede interpretarse como VQE con el observable:\n",
        "\n",
        "$$\n",
        "\\hat{H_2} := \\hat{H_1} + \\beta_1 |\\psi(\\vec{\\theta^1})\\rangle \\langle \\psi(\\vec{\\theta^1})|\n",
        "\\quad \\Rightarrow \\quad\n",
        "C_2(\\vec{\\theta}) = \\langle \\psi(\\vec{\\theta}) | \\hat{H_2} | \\psi(\\vec{\\theta})\\rangle.\n",
        "$$\n",
        "\n",
        "Si la solución a este nuevo problema es $|\\psi(\\vec{\\theta^2})\\rangle$, el valor esperado de $\\hat{H}$ (no $\\hat{H_2}$) debería ser $ \\langle \\psi(\\vec{\\theta^2}) | \\sombrero{H} | \\psi(\\vec{\\theta^2})\\rangle = \\lambda_2$."
      ]
    },
    {
      "attachments": {
      },
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "Análogamente, para obtener el valor propio $k$-th $\\lambda_{k-1}$, minimizaría la función de costo:\n",
        "\n",
        "$$\n",
        "C_{k-1}(\\vec{\\theta}) :=\n",
        "C_{k-2}(\\vec{\\theta}) + \\beta_{k-2} |\\langle \\psi(\\vec{\\theta})| \\psi(\\vec{\\theta^{k-2}})\\rangle  |^2,\n",
        "$$\n",
        "\n",
        "Recuerda que definimos $\\vec{\\theta^j}$ tal que $\\langle \\psi(\\vec{\\theta^j}) | \\sombrero{H} | \\psi(\\vec{\\theta^j})\\rangle = \\lambda_j, \\forall j&lt;k$. Este problema es equivalente a minimizar $C(\\vec{\\theta}) = \\langle \\psi(\\vec{\\theta}) | \\sombrero{H} | \\psi(\\vec{\\theta})\\rangle$ pero con la restricción de que el estado debe ser ortogonal a $|\\psi(\\vec{\\theta^j})\\rangle ; \\forall j \\in {0, \\cdots, k-1}$, restringiendo así el espacio de búsqueda al subespacio correspondiente a los valores propios {$\\lambda_{k-1},\\cdots,\\lambda_{N-1}$ }.\n",
        "\n",
        "Este problema es equivalente a un VQE con el observable:\n",
        "\n",
        "$$\n",
        "\\hat{H}_{k-1} :=\n",
        "\\hat{H}_{k-2} + \\beta_{k-2} |\\psi(\\vec{\\theta^{k-2}})\\rangle \\langle \\psi(\\vec{\\theta^{k-2}})|\n",
        "\\quad \\Rightarrow \\quad\n",
        "C_{k-1}(\\vec{\\theta}) = \\langle \\psi(\\vec{\\theta}) | \\hat{H}_{k-1} | \\psi(\\vec{\\theta})\\rangle,\n",
        "$$\n",
        "\n",
        "Como puede ver en el proceso, para obtener el valor propio $k$-th, necesita los estados propios (aproximados) de los valores propios anteriores de $k-1$, por lo que necesitaría ejecutar VQE un total de $k$ veces. Por lo tanto, la función de costo de VQD es la siguiente:\n",
        "\n",
        "$$\n",
        "C_k(\\vec{\\theta}) =\n",
        "\\langle \\psi(\\vec{\\theta}) | \\hat{H} | \\psi(\\vec{\\theta})\\rangle +\n",
        "\\sum_{j=0}^{k-1}\\beta_j |\\langle \\psi(\\vec{\\theta})| \\psi(\\vec{\\theta^j})\\rangle |^2\n",
        "$$\n",
        "\n",
        "El diseño de VQD se puede resumir de la siguiente manera:\n",
        "\n",
        "- Preparar un operador de referencia $U_R$\n",
        "- Aplique la forma variacional $U_V(\\vec\\theta_{i,j})$ al estado de referencia, creando el siguiente ansatze $U_A(\\vec\\theta_{i,j})$\n",
        "- Bootstrap en $i=0$ si tenemos un problema similar (típicamente encontrado a través de simulación clásica o muestreo).\n",
        "- Evalúe la función de costo $C_k(\\vec{\\theta})$, que implica calcular $k$ estados excitados y una matriz de $\\beta$ que definen la penalización por superposición para cada término superpuesto.\n",
        "    - Calcule el valor esperado para un $\\langle \\psi_{j}(\\vec{\\theta}) | \\sombrero{H} | \\psi_{j}(\\vec{\\theta}) \\rangle$ para cada $k$\n",
        "    - Calcula la penalización $\\sum_{j=0}^{k-1}\\beta_j |\\langle \\psi(\\vec{\\theta})| \\psi(\\vec{\\theta^j})\\rangle |^2$.\n",
        "    - La función de costo debe devolver la suma de estos dos términos\n",
        "- Utilice un optimizador clásico para elegir el siguiente conjunto de parámetros $\\Theta_{i+1}$.\n",
        "- Repita este proceso hasta que se alcance la convergencia."
      ]
    },
    {
      "attachments": {
      },
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "## Regresión de muestreo cuántico (QSR)\n",
        "\n",
        "Uno de los principales problemas con VQE son las múltiples llamadas a una computadora cuántica que se requieren para obtener los parámetros para cada paso, incluidos $k$, $k-1$, etc. Esto es especialmente problemático cuando el acceso a los dispositivos cuánticos está en cola. . Si bien una [`Session`](https://qiskit.org/documentation/partners/qiskit_ibm_runtime/how_to/run_session.html) se puede usar para agrupar varias llamadas iterativas, un enfoque alternativo es usar el muestreo. Al utilizar recursos más clásicos, podemos completar el proceso de optimización completo en una sola llamada. Aquí es donde entra en juego [la regresión de muestreo cuántico](https://arxiv.org/pdf/2012.02338) . Dado que el acceso a las computadoras cuánticas sigue siendo un producto de baja oferta/alta demanda, encontramos que esta compensación es posible y conveniente para muchos estudios actuales. Este enfoque aprovecha todas las capacidades clásicas disponibles al mismo tiempo que captura muchos de los mecanismos internos y las propiedades intrínsecas de los cálculos cuánticos que no aparecen en la simulación.\n",
        "\n",
        "![QSR](images/instances_QSR.png)\n",
        "\n",
        "La idea detrás de QSR es que la función de costo $C(\\theta) := \\langle \\psi(\\theta) | \\sombrero{H} | \\psi(\\theta)\\rangle$ se puede expresar como una serie de Fourier de la siguiente manera:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "C(\\vec{\\theta})\n",
        "\n",
        "&amp; := \\langle \\psi(\\theta) | \\hat{H} | \\psi(\\theta)\\rangle \\\\[1mm]\n",
        "\n",
        "&amp; := a_0 + \\sum_{k=1}^S[a_k\\cos(k\\theta)+ b_k\\sin(k\\theta)] \\\\[1mm]\n",
        "\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Dependiendo de la periodicidad y el ancho de banda de la función original, el conjunto $S$ puede ser finito o infinito. Para los propósitos de esta discusión, supondremos que es infinito. El siguiente paso es muestrear la función de costo $C(\\theta)$ varias veces para obtener los coeficientes de Fourier ${a_0, a_k, b_k}_{k=1}^S$. Específicamente, dado que tenemos $2S+1$ de incógnitas, necesitaremos muestrear la función de costo $2S+1$ veces.\n",
        "\n",
        "Si luego muestreamos la función de costo para los valores de parámetro $2S+1$ {$\\theta_1,...,\\theta_{2S+1}$}, podemos obtener el siguiente sistema:\n",
        "\n",
        "$$\n",
        "\\begin{pmatrix} 1 &amp; \\cos(\\theta_1) &amp; \\sin(\\theta_1) &amp; \\cos(2\\theta_1) &amp; ... &amp; \\sin(S\\theta_1) \\\\\n",
        "1 &amp; \\cos(\\theta_2) &amp; \\sin(\\theta_2) &amp; \\cos(2\\theta_2) &amp; \\cdots &amp; \\sin(S\\theta_2)\\\\\n",
        "\\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\\n",
        "1 &amp; \\cos(\\theta_{2S+1}) &amp; \\sin(\\theta_{2S+1}) &amp; \\cos(2\\theta_{2S+1}) &amp; \\cdots &amp; \\sin(S\\theta_{2S+1})\n",
        "\\end{pmatrix} \\begin{pmatrix} a_0 \\\\ a_1 \\\\ b_1 \\\\ a_2 \\\\ \\vdots \\\\ b_S \\end{pmatrix} = \\begin{pmatrix} C(\\theta_1) \\\\ C(\\theta_2) \\\\ \\vdots \\\\ C(\\theta_{2S+1}) \\end{pmatrix},\n",
        "$$\n",
        "\n",
        "que reescribiremos como\n",
        "\n",
        "$$\n",
        "Fa=c.\n",
        "$$\n",
        "\n",
        "En la práctica, este sistema generalmente no es consistente porque los valores de la función de costo $c$ no son exactos. Por lo tanto, suele ser una buena idea normalizarlos multiplicándolos por $F^\\dagger$ a la izquierda, lo que da como resultado:\n",
        "\n",
        "$$\n",
        "F^\\dagger Fa = F^\\dagger c.\n",
        "$$\n",
        "\n",
        "Este nuevo sistema siempre es consistente y su solución es una solución de mínimos cuadrados al problema original. Si tenemos $k$ parámetros en lugar de uno solo, y cada parámetro $\\theta^i$ tiene su propio $S_i$ para $i \\in {1,...,k}$, entonces el número total de muestras requeridas es:\n",
        "\n",
        "$$\n",
        "T=\\prod_{i=1}^k(2S_i+1)\\leq \\prod_{i=1}^k(2S_{max}+1) = (2S_{max}+1)^n,\n",
        "$$\n",
        "\n",
        "donde $S_{\\max} = \\max_i(S_i)$. Además, ajustar $S_{\\max}$ como un parámetro ajustable (en lugar de inferirlo) abre nuevas posibilidades, como:\n",
        "\n",
        "- **Sobremuestreo** : para mejorar la precisión.\n",
        "- **Submuestreo** : para aumentar el rendimiento al reducir la sobrecarga del tiempo de ejecución o eliminar los mínimos locales.\n",
        "\n",
        "El diseño de QSR se puede resumir de la siguiente manera:\n",
        "\n",
        "- Preparar operadores de referencia $U_R$\n",
        "    - Pasaremos del estado $|0\\rangle$ al estado de referencia $|\\rho\\rangle$\n",
        "- Aplique la forma variacional $U_V(\\vec\\theta_{i,j})$ para crear un ansatz $U_A(\\vec\\theta_{i,j})$\n",
        "    - Determine el ancho de banda asociado con cada parámetro en el ansatz. Un límite superior es suficiente.\n",
        "- Bootstrap en $i=0$ si tenemos un problema similar (generalmente encontrado a través de simulación clásica o muestreo)\n",
        "- Muestra la función de costo $C(\\vec\\theta) := a_0 + \\sum_{k=1}^S[a_k\\cos(k\\theta)+ b_k\\sin(k\\theta)]$ al menos $T$ veces\n",
        "    - $T=\\prod_{i=1}^k(2S_i+1)\\leq \\prod_{i=1}^k(2S_{máx}+1) = (2S_{máx}+1)^n$\n",
        "    - Decida si sobremuestrear o submuestrear para equilibrar la velocidad frente a la precisión ajustando $T$.\n",
        "- Calcule los coeficientes de Fourier a partir de las muestras (es decir, resuelva el sistema lineal de ecuaciones normalizado).\n",
        "- Resuelva el mínimo global de la función de regresión resultante en una máquina clásica."
      ]
    },
    {
      "attachments": {
      },
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "Con esta lección, aprendió acerca de las múltiples instancias variacionales disponibles:\n",
        "\n",
        "- Disposición general\n",
        "- Introducción de ponderaciones y penalizaciones para ajustar una función de coste\n",
        "- Exploración del submuestreo frente al sobremuestreo para equilibrar la velocidad frente a la precisión\n",
        "\n",
        "Estas ideas se pueden adaptar para formar un algoritmo variacional personalizado que se ajuste a su problema. Le animamos a compartir sus resultados con la comunidad. La siguiente lección explorará cómo usar un algoritmo variacional para resolver una aplicación."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
